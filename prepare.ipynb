{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bad3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for working with arrays and DataFrames\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import acquire library for retrieving telco data\n",
    "import acquire\n",
    "# import library to split our data for use with machine learning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8a43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named prep_telco that accepts the raw telco_df data,\n",
    "# and returns the cleaned data\n",
    "def prep_telco(telco_df):\n",
    "    '''\n",
    "    prep_telco will take in a DataFrame containing data from the Telco dataset.\n",
    "    the function will drop columns 'payment_type_id', 'internet_service_type_id',\n",
    "    'contract_type_id' because they are duplicate due to us joining tables via sql.\n",
    "    The function will then convert 'total_charges' to float type.\n",
    "    Then it will change columns containing only 'yes'/'no' values into 1/0 values\n",
    "    and encore categorical columns to dummies then return the cleaned DataFrame.\n",
    "    '''\n",
    "    # Drop any unnecessary, unhelpful, or duplicated columns. \n",
    "    # 'payment_type_id', 'internet_service_type_id', 'contract_type_id' are redundant\n",
    "    # since we joined tables in the sql query\n",
    "    telco_df = telco_df.drop(columns=\n",
    "                       ['payment_type_id',\n",
    "                        'internet_service_type_id',\n",
    "                        'contract_type_id'])\n",
    "    \n",
    "    # total_charges is showing up as an object type when it actually should be a float\n",
    "    telco_df['total_charges'] = telco_df.total_charges.replace(\n",
    "        ' ','').replace('','0').astype(float)\n",
    "    \n",
    "    # replace yes/no column values with 1/0\n",
    "    telco_df['partner'] = telco_df.partner.map({'Yes': 1, 'No': 0})\n",
    "    telco_df['dependents'] = telco_df.dependents.map({'Yes': 1, 'No': 0})\n",
    "    telco_df['phone_service'] = telco_df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    telco_df['paperless_billing'] = telco_df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "    telco_df['churn'] = telco_df.churn.map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # convert the categorical data into dummies\n",
    "    telco_df = pd.concat(\n",
    "        [telco_df, pd.get_dummies(telco_df[[\n",
    "         'gender',\n",
    "         'multiple_lines',\n",
    "         'online_security',\n",
    "         'online_backup',\n",
    "         'device_protection',\n",
    "         'tech_support',\n",
    "         'streaming_tv',\n",
    "         'streaming_movies',\n",
    "         'contract_type',\n",
    "         'internet_service_type',\n",
    "         'payment_type'\n",
    "        ]], drop_first=True)],\n",
    "                      axis=1)\n",
    "    \n",
    "    # now we have column names with spaces, which we don't want\n",
    "    # let's rename the columns with spaces, remove ()s and lower case everything\n",
    "    new_names = []\n",
    "    for col in telco_df.columns.to_list():\n",
    "        new_names.append(col.replace(' ', '_').replace('(','').replace(')', '').lower())\n",
    "    telco_df.columns = new_names\n",
    "    \n",
    "    # create a column identifying customers with neither online security or\n",
    "    # online backup services\n",
    "    telco_df['neither_security_or_backup'] = ((telco_df.online_backup == 'No') \n",
    "                                   & (telco_df.online_security == 'No'))\n",
    "    \n",
    "    # we now have duplicate columns due to the get_dummies function,\n",
    "    # the columns with _no_internet_service such as online_security_no_internet_service\n",
    "    # are the same info as contained in the internet_service_type_none column\n",
    "    \n",
    "    # return the clean DataFrame\n",
    "    return telco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf28d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening data from file\n"
     ]
    }
   ],
   "source": [
    "telco = prep_telco(acquire.get_telco_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a393b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'gender', 'senior_citizen', 'partner', 'dependents',\n",
       "       'tenure', 'phone_service', 'multiple_lines', 'online_security',\n",
       "       'online_backup', 'device_protection', 'tech_support', 'streaming_tv',\n",
       "       'streaming_movies', 'paperless_billing', 'monthly_charges',\n",
       "       'total_charges', 'churn', 'contract_type', 'internet_service_type',\n",
       "       'payment_type', 'gender_male', 'multiple_lines_no_phone_service',\n",
       "       'multiple_lines_yes', 'online_security_no_internet_service',\n",
       "       'online_security_yes', 'online_backup_no_internet_service',\n",
       "       'online_backup_yes', 'device_protection_no_internet_service',\n",
       "       'device_protection_yes', 'tech_support_no_internet_service',\n",
       "       'tech_support_yes', 'streaming_tv_no_internet_service',\n",
       "       'streaming_tv_yes', 'streaming_movies_no_internet_service',\n",
       "       'streaming_movies_yes', 'contract_type_one_year',\n",
       "       'contract_type_two_year', 'internet_service_type_fiber_optic',\n",
       "       'internet_service_type_none', 'payment_type_credit_card_automatic',\n",
       "       'payment_type_electronic_check', 'payment_type_mailed_check',\n",
       "       'neither_security_or_backup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e876a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle():\n",
    "    '''\n",
    "    The wrangle function will retreive a DataFrame containing the telco dataset\n",
    "    by using the get_telco_data contained in the acquire.py file.\n",
    "    The function will then clean the data using the prep_telco function\n",
    "    '''\n",
    "    # retrieve telco data, and clean the data\n",
    "    telco = prep_telco(acquire.get_telco_data())\n",
    "    # split the data for use in machine learning models\n",
    "#     train, validate, test = split_data(telco)\n",
    "#     # return the split DataFrames\n",
    "#     return train, validate, test\n",
    "    return telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72cb5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, random_seed=4233):\n",
    "    '''\n",
    "    split_data will take in a DataFrame and a stratify target (default to 'churn')\n",
    "    random_seed is also asignable (default = 4233 for no reason).\n",
    "    It will return the data split up for ML models. \n",
    "    The return values are: train, validate, test\n",
    "    '''\n",
    "    \n",
    "    # split our df into train_val and test:\n",
    "    train_val, test = train_test_split(df,\n",
    "                                       train_size=0.8,\n",
    "                                       random_state=random_seed,\n",
    "                                       stratify=df['churn'])\n",
    "    \n",
    "    # split our train_val into train and validate:\n",
    "    train, validate = train_test_split(train_val,\n",
    "                                       train_size=0.7,\n",
    "                                       random_state=random_seed,\n",
    "                                       stratify=train_val['churn'])\n",
    "    # return the split DataFrames\n",
    "    return train, validate, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
